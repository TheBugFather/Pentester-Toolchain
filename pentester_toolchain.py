# pylint: disable=R1719,W0106
"""
This tool may be used for legal purposes only.
Users take full responsibility for any actions performed using this tool.
The author accepts no liability for damage caused by this tool.
If these terms are not acceptable to you, then do not use this tool.

Built-in modules
"""
import asyncio
import logging
import logging.handlers
import re
import sys
import time
try:
    from queue import SimpleQueue as Queue
except ImportError:
    from queue import Queue
from pathlib import Path
# Custom Modules #
from Modules.tcp_handlers import (ftp_handler, ssh_handler, telnet_handler, smtp_handler,
                                  whois_handler, finger_handler, web_handler, pop3_handler,
                                  ident_handler, nntp_handler, imap_handler, smux_handler,
                                  checkpoint_firewall_handler, smb_handler, modbus_handler,
                                  rlogin_handler, rsh_handler, apple_filing_handler, rtsp_handler,
                                  cups_handler, rsync_handler, java_rmi_handler, mssql_handler,
                                  oracle_db_handler, oracle_xmldb_handler, docker_handler,
                                  squid_handler, iscsi_handler, sap_router_handler, sql_handler,
                                  rdp_handler, distcc_handler, subversion_handler, epmd_handler,
                                  cisco_smart_install_handler, postgresql_handler, redshift_handler,
                                  vnc_handler, x11_handler, redis_handler, winrm_handler,
                                  apache_jserv_handler, influxdb_handler, bitcoin_handler,
                                  apache_casandra_handler, raw_printing_handler,
                                  elastic_search_handler, ndmp_handler, memcache_handler,
                                  gluster_fs_handler, mongo_db_handler, hadoop_handler)
from Modules.tcp_udp_handlers import (dns_handler, irc_handler, kerberos_handler, rpc_handler,
                                      ntp_handler, msrpc_handler, netbios_handler, snmp_handler,
                                      ldap_handler, ipsec_ike_vpn_handler, ipmi_handler,
                                      socks_proxy, nfs_handler, rabbit_mq_handler, couchdb_handler,
                                      ethernet_ip_handler)
from Modules.udp_handlers import (dhcp_handler, tftp_handler, ruserd_handler, ws_discovery_handler,
                                  mdns_handler, bacnet_handler)
from Modules.utils import (async_file_handler, async_proc_exec, cmd_parser, column_print,
                           ConfigClass, config_input, file_handler, markdown_formatter, print_err,
                           RegexHandler, ScanConfig, ScanData)


MAX_COLUMNS = 4
QUEUE = Queue()


async def nmap_handler(hostname: str, nmap_path: Path, config: object, re_obj: object):
    """
    Command execution function for nmap initial probing scans.

    :param hostname:  The hostname to be parsed into commands.
    :param nmap_path:  The path to the nmap output file.
    :param config:  Program configuration instance.
    :param re_obj:  Compiled regex instance.
    :return:  Nothing
    """
    # Iterate through adb commands from yaml file #
    for command in config.nmap_init:
        # Check to see if command has delimiter to parse #
        args = [True if delimiter in command else False for delimiter in config.delimiters]

        # If args are to be parsed in command #
        if True in args:
            # Parse in args and split into list #
            command = await cmd_parser(command, re_obj, hostname)

        # Split command into list to grab name #
        cmd_list = command.split()
        print(f'[+] Executing {cmd_list[0]} on {hostname}')

        # Execute system command #
        output = await async_proc_exec(command, config)
        # If the command return data #
        if output:
            data = (f'>> {command}\n{"*" * (len(command) + 4)}\n'
                    f'{output.decode(errors="replace")}\n\n\n')
            # Write the output with command title to service file #
            await async_file_handler(nmap_path, 'a', data=data)


async def scan_event(scan_task_obj: object, regex_obj: object, configs_obj: object,
                     scanner: object):
    """
    Begins by setting up process logging facilities, file paths, and directories. If there are no
    specified ports in config file, nmap scans will be skipped assuming the ports have already been
    enumerated. Otherwise, an initial nmap scan is run, followed by corresponding tool chains
    configured based on regex matching of open ports, finishing with a full nmap scan checking all
    ports.

    :param scan_task_obj:  The scan object containing organizational data such as name, ip,
                           domain, etc.
    :param regex_obj:  The compiled regex instance.
    :param configs_obj:  The program configuration instance from loaded yaml file.
    :param scanner:  The program scan process service function class.
    :return:  Nothing
    """
    # Set file paths for target directory and nmap scans #
    tcp_path = scan_task_obj.out_path / 'TCP_Handlers'
    udp_path = scan_task_obj.out_path / 'UDP_Handlers'
    tcp_udp_path = scan_task_obj.out_path / 'TCP_UDP_Handlers'
    scan_dirs = (tcp_path, udp_path, tcp_udp_path)
    # Iterate through program directory paths and create them #
    for path in scan_dirs:
        path.mkdir(parents=True, exist_ok=True)

    # Set the nmap paths #
    nmap_path = scan_task_obj.out_path / 'Nmap'
    nmap_start = nmap_path / 'nmap_init.txt'
    nmap_end = nmap_path / 'nmap_full.txt'
    # Create the nmap directory #
    nmap_path.mkdir(parents=True, exist_ok=True)

    print(f'[+] Starting initial nmap scan for {scan_task_obj.domain}:{scan_task_obj.ip_addr}')

    # Execute the initial nmap probing scans #
    await nmap_handler(scan_task_obj.ip_addr, nmap_start, configs_obj, regex_obj)
    # Read the nmap probe scans output data #
    scan_data = await async_file_handler(nmap_start, 'r')
    # If nmap scans failed to produce output #
    if not scan_data:
        # Print error, log, and exit #
        print_err(f'Initial nmap scan returned no data on {scan_task_obj.domain}'
                  f':{scan_task_obj.ip_addr}')
        logging.error('Initial nmap scan returned no data on %s:%s', scan_task_obj.domain,
                      scan_task_obj.ip_addr)
        sys.exit(4)

    print(f'[!] Initial nmap scan for {scan_task_obj.domain}:{scan_task_obj.ip_addr}')

    # Set error code for if not properly referenced in loop #
    scan_port = '-1'
    # Run regex operations on port scan output to find open ports #
    re_searches = regex_obj.scan_parse(scan_data)

    print(f'[+] Executing command toolchains on {scan_task_obj.domain}:{scan_task_obj.ip_addr}')

    # Iterate through the regex result from port scan #
    for key, value in re_searches.items():
        # If the regex pattern matched #
        if value:
            # Iterate through split key port list #
            for port in key.split(','):
                # If current port found in match #
                if port in value.group(0):
                    print(f'[+] Port {port} matched on {scan_task_obj.domain}'
                          f':{scan_task_obj.ip_addr}')
                    # Assign as scan port & exit loop #
                    scan_port = port
                    break

            # If the scan port was not found #
            if scan_port == '-1':
                # Print error, log, and exit #
                print_err(f'Port in {key} was not found in {value}')
                logging.error('Port in %s was not found in %s', key, value)
                sys.exit(4)

            try:
                # Execute service handler function #
                await scanner.service_handler[key](scan_dirs, configs_obj, regex_obj,
                                                   [scan_task_obj.ip_addr, scan_task_obj.domain,
                                                    int(scan_port)])
            # If a key is passed in that does not exist #
            except (KeyError, ValueError) as exec_err:
                # Print error, log, and exit #
                print_err('Attempting to access non-existent key in ScanClass func_dict or'
                          f' error converting port to int: {exec_err}')
                logging.error('Attempting to access non-existent key in ScanClass func_dict or'
                              ' error converting port to int: %s', exec_err)
                sys.exit(5)

    print(f'[+] Starting final nmap scan for {scan_task_obj.domain}:{scan_task_obj.ip_addr}')

    # Check and parse the yaml command #
    cmd = await cmd_parser(configs_obj.nmap_final, regex_obj, scan_task_obj.ip_addr)
    # Run final nmap scan on all uncommon ports #
    scan_data = await async_proc_exec(cmd, configs_obj)
    # If the final nmap scan was successful #
    if scan_data:
        print(f'[!] Final nmap scan for {scan_task_obj.domain}'
              f':{scan_task_obj.ip_addr} completed')
        # Write nmap data to output file #
        await async_file_handler(nmap_end, 'w', data=f'>> nmap final scan\n{"*" * 19}\n'
                                                     f'{scan_data.decode(errors="replace")}')
    # If error occurred during final nmap scan #
    else:
        # Print error and log #
        print_err(f'Error occurred on final nmap scan for {scan_task_obj.domain}'
                  f':{scan_task_obj.ip_addr}')
        logging.error('Error occurred on final nmap scan for %s:%s', scan_task_obj.domain,
                      scan_task_obj.ip_addr)

    print(f'[!] Toolchains execution complete for {scan_task_obj.domain}:{scan_task_obj.ip_addr}')


async def task_executor(task_objs: list, config_obj: object, regex_config: object,
                        service_config: object):
    """
    Takes organizational templates and performs DNS resolution to parse the template information
    into the scan object class then appending the result to scan object list.

    :param task_objs:  The list of organizational templates.
    :param config_obj:  The program configuration instance.
    :param regex_config:  The regex compiled pattern library instance.
    :param service_config:  The service class handler function call instance.
    :return:  Nothing
    """
    scan_count = 0
    active_tasks = set()

    # While the program is still running scan events #
    while True:
        # If the scan task status is set to WAITING and the current
        # number of active tasks is below the max threshold #
        if task_objs[scan_count].status == 'WAITING' and len(active_tasks) < config_obj.max_tasks:
            # Create asyncio task in event loop and add it to set for managing finished tasks #
            task = asyncio.create_task(scan_event(task_objs[scan_count], regex_config,
                                                  config_obj, service_config), name=str(scan_count))
            # Set the scan object status to ACTIVE #
            task_objs[scan_count].status = 'ACTIVE'
            active_tasks.add(task)

        # Poll the task set for completed tasks which are saved to another set #
        completed_tasks = {task for task in active_tasks if task.done()}
        # Iterate through completed tasks set #
        for task in completed_tasks:
            # Remove the task from task_objs list by named number reference #
            task_objs.remove(task_objs[int(task.get_name())])
            # Remove task from active tasks set #
            active_tasks.remove(task)

        # If there are no more scan object to pass into event loop
        # and all active tasks are complete #
        if not task_objs and not active_tasks:
            break

        # Increment the scan count until end then loop back to 0 #
        scan_count = (scan_count + 1) % len(task_objs)

        # Small delay to avoid busy waiting #
        await asyncio.sleep(0.1)


async def resolver(target_host: str, regex_obj: object, resolver_path: Path, conf_obj: object):
    """
    Takes the passed in IP or domain hosts and resolves it using the hosts command. If successful,
    the IP and the domain will be returned. On failures, the passed in IP or domain will be
    assigned as both.

    :param target_host:  The target to resolve, either IP address or domain.
    :param regex_obj:  The compiled regex instance.
    :param resolver_path:  The path to the file where the host commands output will go.
    :param conf_obj:  The program configuration instance.
    :return:  The IP address and domain in a tuple grouping.
    """
    # Execute host command on target to lookup ip address or domain depending on input #
    output = await async_proc_exec(f'host {target_host}', conf_obj)
    # If ip/domain resolution was successful #
    if output:
        # Write the output to a file #
        await async_file_handler(resolver_path, 'wb', data=output)

        # If passed in target is ip address #
        if re.search(regex_obj.re_ip, target_host):
            # Attempt to parse out resolved domain name with regex #
            domain_parse = re.search(regex_obj.re_domain_parse, output.decode(errors='replace'))
            # If regex failed to parse resolved domain name #
            if not domain_parse:
                # Attempt to run scan with ip and domain the same (some scans will likely fail) #
                target_ip = target_domain = target_host
            # If resolved domain was parsed by regex #
            else:
                target_ip = target_host
                target_domain = domain_parse.group(0)

        # If passed in target is domain name #
        else:
            # Attempt to parse out resolved ip address with regex #
            ip_parse = re.search(regex_obj.re_ip_parse, output.decode(errors='replace'))
            # If regex failed to parse resolved ip address #
            if not ip_parse:
                # Attempt to run scan with ip and domain the same (some scans will likely fail) #
                target_ip = target_domain = target_host
            # If resolved ip address was parsed by regex #
            else:
                target_ip = ip_parse.group(0)
                target_domain = target_ip

    # If ip/domain resolution was not successful #
    else:
        # Attempt to run scan with ip and domain the same (some scans will likely fail) #
        target_ip = target_domain = target_host

    return target_host, target_ip, target_domain


async def populate_scan_objs(org_templates: list, config_obj: object, regex_config: object) -> list:
    """
    Iterates through the organizational templates and performs DNS resolution and saves the
    resulting IP and domain to a task data object with any other data. Then task data object
    is added to the scan object list then re-iterates until the template list has been traversed.

    :param org_templates:  The list of organization templates for processing.
    :param config_obj:  The program configuration instance.
    :param regex_config:  The regex compiled pattern library instance.
    :return:  The populated list of scan instances for event processing.
    """
    task_obj_list = []

    # Iterate through the organizational templates #
    for org_template in org_templates:
        # Reset the task & temp object list per iteration #
        tasks = []
        temp_obj_list = []

        # Iterate through each host per organizational template #
        for host in org_template.hosts:
            # Format the DNS resolver output file path #
            resolver_path = config_obj.out_dir / org_template.name / host / 'resolver_out.txt'
            # Ensure Output directory exists for current host #
            resolver_path.parent.mkdir(parents=True, exist_ok=True)

            # Initialize ScanData storage class instance for data passed into scan event #
            task_data_obj = ScanData()
            # Populate ScanData storage instance with current organization name #
            task_data_obj.name = org_template.name
            # Set the ip address initially to null #
            task_data_obj.ip_addr = None
            # Set the domain initially to null #
            task_data_obj.domain = None
            # Set the time from organizational template #
            task_data_obj.time = org_template.time
            # Set the output path based on the current iteration #
            task_data_obj.out_path = resolver_path.parent
            # Set the status to waiting #
            task_data_obj.status = 'WAITING'
            # Now that data is populated in ScanData instance, add it to temp scan objects list #
            temp_obj_list.append(task_data_obj)

            # Set up task to perform DNS resolution based on passed domain or IP host #
            task = asyncio.create_task(resolver(host, regex_config, resolver_path, config_obj))
            # Add the task to the tasks list #
            tasks.append(task)

        print(f'[+] Performing DNS resolution for:\n')
        # Print the list of hosts in a column based format #
        await column_print(org_template.hosts, MAX_COLUMNS)

        # Execute all host discovery tasks concurrently and return results as a list #
        dns_results = await asyncio.gather(*tasks)
        # Set task object list as iterator #
        temp_obj_list_iter = iter(temp_obj_list)
        is_traversed = False

        # Re-iterate through each host in template #
        for host in org_template.hosts:
            # If the iterator has been traversed #
            if is_traversed:
                break

            # Iterate through the resulting data from the concurrent dns lookup data #
            for data in dns_results:
                # Unpack the tuple containing dns results #
                task_host, ip_addr, domain = data
                # If the task host is equal to the current iteration #
                if task_host == host:
                    # Set iterator to the next item #
                    temp_obj_list_iter = next(temp_obj_list_iter, None)
                    # If the iterator has been traversed #
                    if not temp_obj_list_iter:
                        # Set finished boolean toggle to true #
                        is_traversed = True
                        break

                    # Set the task object ip address and domain based on counter offset #
                    temp_obj_list_iter.ip_addr = ip_addr
                    temp_obj_list_iter.domain = domain
                    break

        # Add the members of the temp object list to task object list #
        task_obj_list += temp_obj_list

    return task_obj_list


def sort_templates(template_list: list) -> list:
    """
    Takes the passed in list of scan template classes and sorts them according based on their times.
    The list will be sorted based on times with null times at the end of the list.

    :param template_list:  The input template class list to be sorted.
    :return:  The sorted template class list.
    """
    sorted_templates = []
    null_times = []
    head = 0

    # While templates exist in unsorted list #
    while template_list:
        # If the template time is null (not set) #
        if not template_list[head].time:
            # Add it to the null times (first come first serve) #
            null_times.append(template_list[head])
            # Remote template from template list #
            template_list.remove(template_list[head])
        # If the template time is set #
        else:
            # If the sorted templates list is empty #
            if not sorted_templates:
                # Append current template as head #
                sorted_templates.append(template_list[head])
                # Remove template from template list #
                template_list.remove(template_list[head])
            # If the sorted template list has data #
            else:
                tmp_count = 0
                # Iterate through sorted template list #
                for sorted_template in sorted_templates:
                    # TODO:  this needs work and a better time execution system
                    # If the current client template time is less than the current iteration
                    # in the sorted list or the next iteration time is null #
                    if ((template_list[head].time < sorted_template[tmp_count].time)
                    or not sorted_template[tmp_count].time):
                        # Insert current template before identified index in sorted template list #
                        sorted_templates.insert(tmp_count, template_list[head])
                        # Remove template from template list #
                        template_list.remove(template_list[head])
                        break

                    tmp_count += 1

    # If client templates were detected with null times #
    if null_times:
        # Append clients with null times to the end of the list #
        sorted_templates += null_times

    return sorted_templates


async def host_discovery(config_obj: object, regex_obj: object, template_list: list) -> list:
    """
    Iterates through list of organizational templates and performs various forms of host discovery
    to ensure the hosts in organizational templates are actually active before further scanning.

    :param config_obj:  The program configuration instance.
    :param regex_obj:  The program regex compiled pattern library instance.
    :param template_list:  The list of organizational templates to perform host discovery.
    :return:  The list of organizational templates with populated active hosts.
    """
    top100_tcp = ('7,9,13,21-23,25-26,37,53,79-81,88,106,110-111,113,119,135,139,143-144,179,199,'
                  '389,427,443-445,465,513-515,543-544,548,554,587,631,646,873,990,993,995,'
                  '1025-1029,1110,1433,1720,1723,1755,1900,2000-2001,2049,2121,2717,3000,3128,'
                  '3306,3389,3986,4899,5000,5009,5051,5060,5101,5190,5357,5432,5631,5666,5800,'
                  '5900,6000-6001,6646,7070,8000,8008-8009,8080-8081,8443,8888,9100,9999-10000,'
                  '32768,49152-49157')
    top100_udp = ('7,9,17,19,49,53,67-69,80,88,111,120,123,135-139,158,161-162,177,427,443,445,'
                  '497,500,514-515,518,520,593,623,626,631,996-999,1022-1023,1025-1030,1433-1434,'
                  '1645-1646,1701,1718-1719,1812-1813,1900,2000,2048-2049,2222-2223,3283,3456,'
                  '3703,4444,4500,5000,5060,5353,5632,9200,10000,17185,20031,30718,31337,'
                  '32768-32769,32771,32815,33281,49152-49154,49156,49181-49182,49185-49186,49188,'
                  '49190-49194,49200-49201,65024')

    # Iterate through list of client templates #
    for template in template_list:
        # Reset the discovered host & task list per iteration #
        tasks = []
        discovered_hosts = []

        # While the count is less than the max index #
        for host in template.hosts:
            # Perform host discovery on current IP, range of IPs, or network CIDR #
            task = asyncio.create_task(async_proc_exec(f'nmap -sn -PE -PP -PS{top100_tcp} '
                                                       f'-PA{top100_tcp} -PU{top100_udp} {host}',
                                                       config_obj))
            # Add host discovery task to task list #
            tasks.append(task)

        print(f'[+] Performing host discovery for:\n')
        # Print the list of hosts in a column based format #
        await column_print(template.hosts, MAX_COLUMNS)

        # Execute all host discovery tasks concurrently and return results as a list #
        discovery_results = await asyncio.gather(*tasks)

        # Iterate through result data of executed host discovery tasks #
        for data in discovery_results:
            # Run regex search on host discovery output data to confirm active hosts #
            discovery_matches = re.findall(regex_obj.re_host_discovery,
                                           data.decode(errors='replace'))
            # If the host discovery attempt failed to return data or the output has no hosts #
            if data and discovery_matches:
                print(f'[!] {len(discovery_matches)} host(s) identified during discovery')

                # Iterate through list of regex host discovery matches #
                for match in discovery_matches:
                    # Attempt to parse out IP address from host discovery match #
                    ip_addr = re.search(regex_obj.re_ip, match)
                    # If an IP address was matched/parsed #
                    if ip_addr:
                        # Append Ip address to discovered host list ##
                        discovered_hosts.append(ip_addr.group(0))

        print()
        # Reset the current template host list to discovered hosts #
        template.hosts = discovered_hosts

    return template_list


def template_loader(conf_obj: object, regex_obj: object) -> list:
    """
    Iterates through the template files in the Active directory and loads their yaml data in to a
    scan object instance, which is then added to the template list.

    :param conf_obj:  The program configuration instance.
    :param regex_obj:  The regex compiled pattern library instance.
    :return:  The populated scan template list.
    """
    templates = []

    # Iterate through the scan templates in the Templates dir #
    for item in conf_obj.template_path.iterdir():
        # If the current item is a file and has YAML file extension #
        if item.is_file() and item.name.endswith('.yml'):
            # Format the current iteration file path #
            template_path = conf_obj.template_path / item.name
            # Load the yaml data from disk #
            template_data = file_handler(template_path, 'r', yaml=True)
            # Initialize organizational template instance #
            scan_obj = ScanConfig()
            # Parse in organizational data from yaml with validation methods #
            scan_obj.parse_name(template_data['organizational']['name'])
            scan_obj.parse_hosts(template_data['organizational']['hosts'], regex_obj)
            scan_obj.parse_time(template_data['organizational']['time'])
            # Append client template class to template list #
            templates.append(scan_obj)

    return templates


class ServiceClass:
    """
    The scan process service handler class, which maps the ports of interest to their associated
    service handler function to later be referenced for execution.
    """
    service_handler = {
        # TCP handler functions #
        '20,21': ftp_handler,
        '22': ssh_handler,
        '23': telnet_handler,
        '25,465,587,2525': smtp_handler,
        '43': whois_handler,
        '79': finger_handler,
        '80,443,8080,8443': web_handler,
        '110,995': pop3_handler,
        '113': ident_handler,
        '119,433': nntp_handler,
        '143,993': imap_handler,
        '199': smux_handler,
        '264': checkpoint_firewall_handler,
        '445': smb_handler,
        '502': modbus_handler,
        '513': rlogin_handler,
        '514': rsh_handler,
        '548': apple_filing_handler,
        '554': rtsp_handler,
        '631': cups_handler,
        '873': rsync_handler,
        '1050,1098,1099': java_rmi_handler,
        '1433': mssql_handler,
        '1521': oracle_db_handler,
        '2100': oracle_xmldb_handler,
        '2375,2376': docker_handler,
        '3128': squid_handler,
        '3260': iscsi_handler,
        '3299': sap_router_handler,
        '3306': sql_handler,
        '3389': rdp_handler,
        '3632': distcc_handler,
        '3690': subversion_handler,
        '4369': epmd_handler,
        '4786': cisco_smart_install_handler,
        '5432,5433': postgresql_handler,
        '5439': redshift_handler,
        '5800,5900': vnc_handler,
        '5985,5986': winrm_handler,
        '6000': x11_handler,
        '6379': redis_handler,
        '8009': apache_jserv_handler,
        '8086': influxdb_handler,
        '8333,18333,18444,38333': bitcoin_handler,
        '9042,9160': apache_casandra_handler,
        '9100': raw_printing_handler,
        '9200': elastic_search_handler,
        '10000': ndmp_handler,
        '11210': memcache_handler,
        '24007,24008,24009,49152': gluster_fs_handler,
        '27017,27018': mongo_db_handler,
        '50030,50060,50070,50075,50090': hadoop_handler,

        # UDP handler functions #
        '67': dhcp_handler,
        '69': tftp_handler,
        '1026': ruserd_handler,
        '3702': ws_discovery_handler,
        '5353': mdns_handler,
        '47808': bacnet_handler,

        # TCP/UDP handler functions #
        '53': dns_handler,
        '88': kerberos_handler,
        '111': rpc_handler,
        '123': ntp_handler,
        '135': msrpc_handler,
        '137,138,139': netbios_handler,
        '161,162,10161,10162': snmp_handler,
        '194,529,6667': irc_handler,
        '389,636,3268,3269': ldap_handler,
        '500,1723': ipsec_ike_vpn_handler,
        '623': ipmi_handler,
        '1080': socks_proxy,
        '2049': nfs_handler,
        '5671,5672': rabbit_mq_handler,
        '5984,6984': couchdb_handler,
        '44818': ethernet_ip_handler
    }


def main():
    """
    Loads the config file, depending on config file settings, either runs ping scan to identify
    hosts or already has target host in config file, and launches the scan process on target hosts
    based on the available number of cpu's.

    :return:  Nothing
    """
    # Get the current working directory #
    cwd = Path.cwd()

    # If potential yaml config file passed into to program #
    if len(sys.argv) > 1:
        # Format passed in argument as path #
        config_path = cwd / 'Configs' / sys.argv[1]

        # If the passed in configuration file does not exist or is not a yaml file #
        if not config_path.exists() or not str(config_path).endswith('yml'):
            # Prompt user for yaml config file #
            config_path = config_input(cwd)

    # If no args were passed in #
    else:
        # Prompt user for yaml config file #
        config_path = config_input(cwd)

    # Load the YAML configuration file #
    config_data = file_handler(config_path, 'r', yaml=True)
    # Parse program config data into class #
    config_obj = ConfigClass(cwd, config_data)

    # Compile program regex and return as instance #
    re_obj = RegexHandler()
    # Initialize scan service function class #
    service_obj = ServiceClass()

    print(f'+{"=" * 98}+')
    print(r'''
                                                                               .:oxxxdc,            
                                                                           .;xXMMMMMMMMMWO,         
                                                                        'oKMMMMMMWOxxOXMMMMO        
                                                       .;::;'.      .:kNMMMMMMKo'      '0MMMK.      
                                                   'o0MMMMMMMMKo.'o0MMMMMMWkc.           kMMMN.     
                                               .:kNMMMMMMMWMMMMMMMMMMMMKd,                oMMMW,    
                             ...            'oKMMMMMMWOc.  .0MMMMMMWOc.                    cMMMW.   
                         ,dKWMMMWKx:    .:kWMMMMMMKd,     .XMMMMXd,'ck.                     dMMMx   
                     .:kWMMMMMMMMMMMWxoKMMMMMMWk:.        0MMMW:  :MMMW'                    dMMMx   
                  'o0MMMMMMXd;'';oNMMMMMMMW0l'            MMMMl    cMMMW'                  cMMMW.   
               ,xNWWWWWW0c.      lWWWWWXx; .              NWWWo     oWWWk               ;xNMMMN'    
             .. '.. '  ........ .......... '..   .'. ....  .... .   .....  .      . .  .   kKl      
        .   .c'.o.. c: ' .; :.. l.  '. l.. o.:    x ;.  .;:.  ',l  ;.   ;..c. ;l  c.;, '            
      lXK   .:  l   ' c; .; :     o '. l   o',    x ,'  .,;.  '.l  ;'   ;. :.'.', c. .:'            
    .NMMX.   .  ...    .    ... .''... ....,...   .   ..   .''..,''. .. ...'.'..,..                 
   .WMMMN:                       cMMMM:  .XMMMo         .l0MMMMNMMMMN0kOKMMMMMXx;                   
   lMMMM.                         ,WMMMo 'NMMd      .:xNMMMMWkc..l0WMMMMMMNkc.                      
   cMMMM                           .XMMMO..x,    ;dKMMMMMKo'        .',,..                          
    XMMMk                         .'.0MMMMOoccoOWMMMMWk:.                                           
    .XMMMO                     'oXMMc ;OMMMMMMMMMMKo,                                               
      0MMMK.                ;xNMMMMNk.   ,cdxxdl,.                                                  
       OMMMX.           .cOWMMMMXd,                                                                 
        xMMMN,       'oKMMMMM0l.                                                                    
         lWMMMXdlclkNMMMMWk:.                                                                       
          .oXMMMMMMMMMKo,                                                                           
             .;coooc,. 
    ''')
    print(f'+{"=" * 98}+')

    # Call the scan template loader function #
    scan_templates = template_loader(config_obj, re_obj)
    # Iterate through populated scan template list and perform host discovery on network CIDRs
    # to add new hosts to organizational templates loaded in memory #
    scan_templates = asyncio.run(host_discovery(config_obj, re_obj, scan_templates))
    # Sort the client templates based on scan time, otherwise first come first serve #
    sorted_templates = sort_templates(scan_templates)

    # Populate the scan object data list for passing into scan events #
    task_objs = asyncio.run(populate_scan_objs(sorted_templates, config_obj, re_obj))
    # Launch asynchronous event processing function #
    asyncio.run(task_executor(task_objs, config_obj, re_obj, service_obj))

    # If markdown generate from output is set to True in config file #
    if config_obj.markdown:
        # Crawl through the Output director and copy text format to markdown #
        markdown_formatter(config_obj.out_dir, root_logger, re_obj)

    print(f'+{"=" * 98}+')


class LocalQueueHandler(logging.handlers.QueueHandler):
    """
    Acts as the thread handler that processes logging records in queue.
    """
    def emit(self, record: logging.LogRecord):
        """
        Takes a record from the logging queue listener and enqueues the record to the local
        logging system

        :param record:  The logging record to be handled.
        :return:  Nothing
        """
        try:
            # Add log record to the logging queue #
            self.enqueue(record)

        # If async task was already cancelled #
        except asyncio.CancelledError:
            raise

        # If unknown exception occurred #
        except Exception:
            self.handleError(record)


def setup_logging(log_formatter: logging.Formatter):
    """
    Moves the log handlers to a separate thread, replacing handlers on the root logger with a
    LocalQueueHandler. After a queue listener is initialized with the original handlers.

    :param log_formatter:  The formatter string for the file logger.
    :return:  Nothing
    """
    handlers = []
    # Get the root logging handler #
    root = logging.getLogger()
    # Get the local queue handler #
    handler = LocalQueueHandler(QUEUE)
    # Assign local queue handler to root handler #
    root.addHandler(handler)

    # Iterate through the root handlers #
    for current_handler in root.handlers[:]:
        # If the current iteration is not a handler #
        if current_handler is not handler:
            # Remove handler from the root handlers #
            root.removeHandler(current_handler)
            # Add handler to handlers list #
            handlers.append(current_handler)

    # Establish logging queue listener with extracted root handlers and start handler #
    listener = logging.handlers.QueueListener(QUEUE, *handlers, respect_handler_level=True)
    listener.start()

    # Create a file handler that writes logging output to a file handler #
    file_handle = logging.FileHandler('pentester_toolchain.log')
    file_handle.setLevel(logging.DEBUG)
    # Set the formatter for the file logger #
    file_handle.setFormatter(log_formatter)


if __name__ == '__main__':
    RET = 0
    # Record the start time #
    start_time = time.perf_counter()
    # Establish logging formatter #
    formatter = logging.Formatter('%(asctime)s %(lineno)4d@%(filename)-24s[%(levelname)s]>>'
                                  '  %(message)s')
    # Setup asyncio based logging system #
    setup_logging(formatter)
    # Get the root logger #
    root_logger = logging.getLogger()
    # Create a handler using the LocalQueueHandler #
    queue_handler = LocalQueueHandler(QUEUE)
    # Set the formatter for the root logger #
    queue_handler.setFormatter(formatter)
    # Add the queue handler to the root logger #
    root_logger.addHandler(queue_handler)

    try:
        main()

    # If unknown exception occurs #
    except Exception as ex:
        # Print error, log, and set error return code #
        print_err(f'Unknown exception occurred: {ex}')
        logging.exception('Unknown exception occurred: %s', ex)
        RET = 1

    # Record the finish time #
    exec_time = time.perf_counter() - start_time
    # Print and log total execution time #
    print(f'\n[!] Execution time: {exec_time}')
    logging.info('Execution time: %s', exec_time)

    sys.exit(RET)
