# pylint: disable=R1719,W0106
"""
This tool may be used for legal purposes only.
Users take full responsibility for any actions performed using this tool.
The author accepts no liability for damage caused by this tool.
If these terms are not acceptable to you, then do not use this tool.

Built-in modules
"""
import asyncio
import logging
import logging.handlers
import re
import sys
import time
try:
    from queue import SimpleQueue as Queue
except ImportError:
    from queue import Queue
from pathlib import Path
# Custom Modules #
from Modules.tcp_handlers import (ftp_handler, ssh_handler, telnet_handler, smtp_handler,
                                 whois_handler, finger_handler, web_handler, pop3_handler,
                                 ident_handler, nntp_handler, imap_handler, smux_handler,
                                 checkpoint_firewall_handler, smb_handler, modbus_handler,
                                 rlogin_handler, rsh_handler, apple_filing_handler, rtsp_handler,
                                 cups_handler, rsync_handler, java_rmi_handler, mssql_handler,
                                 oracle_db_handler, oracle_xmldb_handler, docker_handler,
                                 squid_handler, iscsi_handler, sap_router_handler, sql_handler,
                                 rdp_handler, distcc_handler, subversion_handler, epmd_handler,
                                 cisco_smart_install_handler, postgresql_handler, redshift_handler,
                                 vnc_handler, x11_handler, redis_handler, winrm_handler,
                                 apache_jserv_handler, influxdb_handler, bitcoin_handler,
                                 apache_casandra_handler, raw_printing_handler,
                                 elastic_search_handler, ndmp_handler, memcache_handler,
                                 gluster_fs_handler, mongo_db_handler, hadoop_handler)
from Modules.tcp_udp_handlers import (dns_handler, irc_handler, kerberos_handler, rpc_handler,
                                     ntp_handler, msrpc_handler, netbios_handler, snmp_handler,
                                     ldap_handler, ipsec_ike_vpn_handler, ipmi_handler,
                                     socks_proxy, nfs_handler, rabbit_mq_handler, couchdb_handler,
                                     ethernet_ip_handler)
from Modules.udp_handlers import (dhcp_handler, tftp_handler, ruserd_handler, ws_discovery_handler,
                                  mdns_handler, bacnet_handler)
from Modules.utils import (async_proc_exec, cmd_parser, ConfigClass, config_input, file_handler,
                           markdown_formatter, print_err, RegexHandler, ScanConfig, ScanData)


queue = Queue()


def nmap_handler(hostname: str, nmap_path: Path, config: object, re_obj: object, log_tuple: tuple):
    """
    Command execution function for nmap initial probing scans.

    :param hostname:  The hostname to be parsed into commands.
    :param nmap_path:  The path to the nmap output file.
    :param config:  Program configuration instance.
    :param re_obj:  Compiled regex instance.
    :param log_tuple:  Tuple containing console and scan_process loggers.
    :return:  Nothing
    """
    # Iterate through adb commands from yaml file #
    for command in config.nmap_init:
        # Check to see if command has delimiter to parse #
        args = [True if delimiter in command else False for delimiter in config.delimiters]

        # If args are to be parsed in command #
        if True in args:
            # Parse in args and split into list #
            command = cmd_parser(command, re_obj, hostname)

        # Split command into list to grab name #
        cmd_list = command.split()
        log_tuple[0].log(logging.INFO, '[+] Executing %s on %s', cmd_list[0], hostname)

        # Execute system command #
        output = system_cmd(command, None, config, log_tuple[1])
        # If the command return data #
        if output:
            data = f'>> {command}\n{"*" * (len(command) + 4)}\n{output.decode()}\n\n\n'
            # Write the output with command title to service file #
            file_handler(nmap_path, 'a', data=data)


async def scan_event(scan_obj: object, regex_obj: object, configs_obj: object, service_conf: object):
    """
    Begins by setting up process logging facilities, file paths, and directories. If there are no
    specified ports in config file, nmap scans will be skipped assuming the ports have already been
    enumerated. Otherwise, an initial nmap scan is run, followed by corresponding tool chains
    configured based on regex matching of open ports, finishing with a full nmap scan checking all
    ports.

    :param scan_obj:  The scan object containing organizational data like name, ip, domain, etc.
    :param regex_obj:  The compiled regex instance.
    :param configs_obj:  The program configuration instance from loaded yaml file.
    :param service_conf:  The program scan process service function class.
    :return:  Nothing
    """
    # Set file paths for target directory and nmap scans #
    host_path = base_path / target_host
    resolver_path = host_path / 'resolver_out.txt'
    tcp_path = host_path / 'TCP_Handlers'
    udp_path = host_path / 'UDP_Handlers'
    tcp_udp_path = host_path / 'TCP_UDP_Handlers'
    scan_dirs = (host_path, tcp_path, udp_path, tcp_udp_path)
    # Iterate through program directory paths and create them #
    [path.mkdir(parents=True, exist_ok=True) for path in scan_dirs]

    # TODO review IP to domain resolver and production concerns with cloud environments, etc.
    # Attempt to resolve the IP/domain depending on whether IP/domain is passed in #
    target_ip, target_domain = resolver(target_host, regex_obj, configs_obj, outs_scan,
                                        resolver_path)
    # Set the nmap paths #
    nmap_path = host_path / 'Nmap'
    nmap_start = nmap_path / 'nmap_init.txt'
    nmap_end = nmap_path / 'nmap_full.txt'
    # Create the nmap directory #
    nmap_path.mkdir(parents=True, exist_ok=True)

    outs_scan[0].log(logging.INFO, '[+] Starting initial nmap scan for %s:%s',
                     target_domain, target_ip)

    # Execute the initial nmap probing scans #
    nmap_handler(target_ip, nmap_start, configs_obj, regex_obj, outs_scan)
    # Read the nmap probe scans output data #
    scan_data = file_handler(nmap_start, 'r', outs_scan[1])
    # If nmap scans failed to produce output #
    if not scan_data:
        # Print error, log, and exit #
        print_err(f'Initial nmap scan returned no data on {target_domain}:{target_ip}')
        outs_scan[1].log(logging.ERROR, 'Initial nmap scan returned no data on %s:%s',
                         target_domain, target_ip)
        sys.exit(4)

    outs_scan[0].log(logging.INFO, '[!] Initial nmap scan for %s:%s completed',
                     target_domain, target_ip)

    # Set error code for if not properly referenced in loop #
    scan_port = '-1'
    # Run regex operations on port scan output to find open ports #
    re_searches = regex_obj.scan_parse(scan_data)

    outs_scan[0].log(logging.INFO, '[+] Executing command toolchains on %s:%s',
                     target_domain, target_ip)

    # Iterate through the regex result from port scan #
    for key, value in re_searches.items():
        # If the regex pattern matched #
        if value:
            # Iterate through split key port list #
            for port in key.split(','):
                # If current port found in match #
                if port in value.group(0):
                    outs_scan[0].log(logging.INFO, '[+] Port %s matched on %s:%s', port,
                                     target_domain, target_ip)
                    # Assign as scan port & exit loop #
                    scan_port = port
                    break

            # If the scan port was not found #
            if scan_port == '-1':
                # Print error, log, and exit #
                print_err(f'Port in {key} was not found in {value}')
                outs_scan[1].log(logging.ERROR, 'Port in %s was not found in %s', key, value)
                sys.exit(4)

            try:
                # Execute service handler function #
                service_conf.service_handler[key](scan_dirs, configs_obj, regex_obj, outs_scan,
                                                  [target_ip, target_domain, int(scan_port)])

            # If a key is passed in that does not exist #
            except (KeyError, ValueError) as exec_err:
                # Print error, log, and exit #
                print_err('Attempting to access non-existent key in ScanClass func_dict or'
                          f'error converting port to int: {exec_err}')
                outs_scan[1].log(logging.ERROR, 'Attempting to access non-existent key in'
                                                'ScanClass func_dict or error converting port '
                                                'to int: %s', exec_err)
                sys.exit(5)

    outs_scan[0].log(logging.INFO, '[+] Starting final nmap scan for %s:%s',
                     target_domain, target_ip)

    # Check and parse the yaml command #
    cmd = cmd_parser(configs_obj.nmap_final, regex_obj, target_ip)
    # Run final nmap scan on all uncommon ports #
    scan_data = system_cmd(cmd, None, configs_obj, outs_scan[1])
    # If the final nmap scan was successful #
    if scan_data:
        outs_scan[0].log(logging.INFO, '[!] Final nmap scan for %s:%s completed',
                         target_domain, target_ip)
        # Write nmap data to output file #
        file_handler(nmap_end, 'w', data=f'>> nmap final scan\n{"*" * 19}\n{scan_data.decode()}')
    # If error occurred during final nmap scan #
    else:
        # Print error and log #
        print_err(f'Error occurred on final nmap scan for {target_domain}:{target_ip}')
        outs_scan[1].log(logging.ERROR, 'Error occurred on final nmap scan for %s:%s',
                         target_domain, target_ip)

    outs_scan[0].log(logging.INFO, '[!] Toolchain execution complete for %s:%s',
                     target_domain, target_ip)


async def resolver(target_host: str, regex_obj: object, resolver_path: Path):
    """
    Takes the passed in IP or domain hosts and resolves it using the hosts command. If successful,
    the IP and the domain will be returned. On failures, the passed in IP or domain will be
    assigned as both.

    :param target_host:  The target to resolve, either IP address or domain.
    :param regex_obj:  The compiled regex instance.
    :param resolver_path:  The path to the file where the host commands output will go.
    :return:  The IP address and domain in a tuple grouping.
    """
    # Execute host command on target to lookup ip address or domain depending on input #
    output = await async_proc_exec(['host', target_host])
    # If ip/domain resolution was successful #
    if output:
        # Write the output to a file #
        file_handler(resolver_path, 'wb', data=output)

        # If passed in target is ip address #
        if re.search(regex_obj.re_ip, target_host):
            # Attempt to parse out resolved domain name with regex #
            domain_parse = re.search(regex_obj.re_domain_parse, output.decode(errors='replace'))
            # If regex failed to parse resolved domain name #
            if not domain_parse:
                # Attempt to run scan with ip and domain the same (some scans will likely fail) #
                target_ip = target_domain = target_host
            # If resolved domain was parsed by regex #
            else:
                target_ip = target_host
                target_domain = domain_parse.group(0)

        # If passed in target is domain name #
        else:
            # Attempt to parse out resolved ip address with regex #
            ip_parse = re.search(regex_obj.re_ip_parse, output.decode(errors='replace'))
            # If regex failed to parse resolved ip address #
            if not ip_parse:
                # Attempt to run scan with ip and domain the same (some scans will likely fail) #
                target_ip = target_domain = target_host
            # If resolved ip address was parsed by regex #
            else:
                target_ip = ip_parse.group(0)
                target_domain = target_ip

    # If ip/domain resolution was not successful #
    else:
        # Attempt to run scan with ip and domain the same (some scans will likely fail) #
        target_ip = target_domain = target_host

    return target_ip, target_domain


async def populate_scan_objs(org_templates: list, config_obj: object,
                             regex_config: object) -> list:
    scan_obj_list = []
    org_count = 0
    scan_count = 0

    # Iterate through the organizational templates #
    while org_count < len(org_templates):
        # Iterate through each host per organizational template #
        while scan_count < len(org_templates[org_count].hosts):
            # Format the DNS resolver output file path #
            resolver_path = (config_obj.cwd / org_templates[org_count].hosts[scan_count]
                             / 'resolver_out.txt')
            # Initialize ScanData storage class instance for data passed into scan event #
            task_data_obj = ScanData()
            # Populate ScanData storage instance with current host data #
            task_data_obj.organization = org_templates[org_count].organization
            # Perform DNS resolution based on passed domain or IP host, results parsed in task obj #
            (task_data_obj.ip_addr,
             task_data_obj.domain) = await resolver(org_templates[org_count].hosts[scan_count],
                                                    regex_config, resolver_path)
            # Set the time from organizational template #
            task_data_obj.time = org_templates[org_count].time
            # Now that data is populated in ScanData instance, add it to scan objects list #
            scan_obj_list.append(task_data_obj)
            scan_count += 1

        org_count += 1
        scan_count = 0

    return scan_obj_list


async def task_executor(org_templates: list, config_obj: object, regex_config: object,
                        service_config: object):
    scan_count = 0
    active_tasks = set()
    # Populate the scan object data list for passing into scan events #
    scan_objs = await populate_scan_objs(org_templates, config_obj, regex_config)

    # While the program is still running scan events #
    while True:
        # Check if you can create a new task based on the threshold #
        if len(active_tasks) < config_obj.max_tasks:
            # Create asyncio task in event loop and add it to set for managing finished tasks #
            task = asyncio.create_task(scan_event(scan_objs[scan_count], regex_config,
                                                  config_obj, service_config))
            active_tasks.add(task)

        # Check for completed tasks and remove them from active_tasks set #
        completed_tasks = {task for task in active_tasks if task.done()}
        # Iterate through completed tasks and remove them #
        for task in completed_tasks:
            active_tasks.remove(task)

        # If there are no more scan object to pass into event loop
        # and all active tasks are complete #
        if not scan_objs and not active_tasks:
            break

        # Increment the scan count until end then loop back to 0 #
        scan_count += 1 % len(scan_objs)

        # Small delay to avoid busy waiting #
        await asyncio.sleep(0.1)

class ServiceClass:
    """
    The scan process service handler class, which maps the ports of interest to their associated
    service handler function to later be referenced for execution.
    """
    service_handler = {
        # TCP handler functions #
        '20,21': ftp_handler,
        '22': ssh_handler,
        '23': telnet_handler,
        '25,465,587,2525': smtp_handler,
        '43': whois_handler,
        '79': finger_handler,
        '80,443,8080,8443': web_handler,
        '110,995': pop3_handler,
        '113': ident_handler,
        '119,433': nntp_handler,
        '143,993': imap_handler,
        '199': smux_handler,
        '264': checkpoint_firewall_handler,
        '445': smb_handler,
        '502': modbus_handler,
        '513': rlogin_handler,
        '514': rsh_handler,
        '548': apple_filing_handler,
        '554': rtsp_handler,
        '631': cups_handler,
        '873': rsync_handler,
        '1050,1098,1099': java_rmi_handler,
        '1433': mssql_handler,
        '1521': oracle_db_handler,
        '2100': oracle_xmldb_handler,
        '2375,2376': docker_handler,
        '3128': squid_handler,
        '3260': iscsi_handler,
        '3299': sap_router_handler,
        '3306': sql_handler,
        '3389': rdp_handler,
        '3632': distcc_handler,
        '3690': subversion_handler,
        '4369': epmd_handler,
        '4786': cisco_smart_install_handler,
        '5432,5433': postgresql_handler,
        '5439': redshift_handler,
        '5800,5900': vnc_handler,
        '5985,5986': winrm_handler,
        '6000': x11_handler,
        '6379': redis_handler,
        '8009': apache_jserv_handler,
        '8086': influxdb_handler,
        '8333,18333,18444,38333': bitcoin_handler,
        '9042,9160': apache_casandra_handler,
        '9100': raw_printing_handler,
        '9200': elastic_search_handler,
        '10000': ndmp_handler,
        '11210': memcache_handler,
        '24007,24008,24009,49152': gluster_fs_handler,
        '27017,27018': mongo_db_handler,
        '50030,50060,50070,50075,50090': hadoop_handler,

        # UDP handler functions #
        '67': dhcp_handler,
        '69': tftp_handler,
        '1026': ruserd_handler,
        '3702': ws_discovery_handler,
        '5353': mdns_handler,
        '47808': bacnet_handler,

        # TCP/UDP handler functions #
        '53': dns_handler,
        '88': kerberos_handler,
        '111': rpc_handler,
        '123': ntp_handler,
        '135': msrpc_handler,
        '137,138,139': netbios_handler,
        '161,162,10161,10162': snmp_handler,
        '194,529,6667': irc_handler,
        '389,636,3268,3269': ldap_handler,
        '500,1723': ipsec_ike_vpn_handler,
        '623': ipmi_handler,
        '1080': socks_proxy,
        '2049': nfs_handler,
        '5671,5672': rabbit_mq_handler,
        '5984,6984': couchdb_handler,
        '44818': ethernet_ip_handler
    }


def sort_templates(template_list: list) -> list:
    """
    Takes the passed in list of scan template classes and sorts them according based on their times.
    The list will be sorted based on times with null times at the end of the list.

    :param template_list:  The input template class list to be sorted.
    :return:  The sorted template class list.
    """
    sorted_templates = []
    null_times = []
    head = 0

    # While templates exist in unsorted list #
    while template_list:
        # If the template time is null (not set) #
        if not template_list[head].time:
            # Add it to the null times (first come first serve) #
            null_times.append(template_list[head])
            # Remote template from template list #
            template_list.remove(template_list[head])

        # If the template time is set #
        else:
            # If the sorted templates list is empty #
            if not sorted_templates:
                # Append current template as head #
                sorted_templates.append(template_list[head])
                # Remove template from template list #
                template_list.remove(template_list[head])
            # If the sorted template list has data #
            else:
                tmp_count = 0
                # Iterate through sorted template list #
                for sorted_template in sorted_templates:
                    # If the current client template time is less than the current iteration
                    # in the sorted list or the next iteration time is null #
                    if template_list[head].time < (sorted_template[tmp_count].time or not
                                                   sorted_template[tmp_count].time):
                        # Insert current template before identified index in sorted template list #
                        sorted_templates.insert(tmp_count, template_list[head])
                        # Remove template from template list #
                        template_list.remove(template_list[head])
                        break

                    tmp_count += 1

    # If client templates were detected with null times #
    if null_times:
        # Append clients with null times to the end of the list #
        sorted_templates += null_times

    return sorted_templates


async def host_discovery(regex_obj: object, template_list: list) -> list:
    """
    Iterates through list of organizational templates and performs various forms of host discovery
    to ensure the hosts in organizational templates are actually active before further scanning.

    :param regex_obj:  The program regex compiled pattern library instance.
    :param template_list:  The list of organizational templates to perform host discovery.
    :return:  The list of organizational templates with populated active hosts.
    """
    count = 0

    # Nmap documentation host discovery examples:
    # -PE -PS80 -PS443 -PP -PU40125 -PS3389 -PA21 -PU161 --source-port 53
    # -PE -PP -PS21,22,23,25,80,113,443,31339 -PA80,113,443,10042 --source-port 53

    # Iterate through list of client templates #
    for template in template_list:
        # While the count is less than the max index #
        while count < len(template.hosts):
            # Perform host discovery on current IP, range of IPs, or network CIDR #
            # TODO: finish host discovery command syntax
            discovery_data = await async_proc_exec(['nmap', '-sn', '', template.hosts[count]])
            # Run regex search on host discovery output data to confirm active hosts #
            discovery_match = re.findall(regex_obj.re_host_discovery, discovery_data)

            # If the host discovery attempt failed to return data or the output has no hosts #
            if not discovery_data or not discovery_match:
                # remove the host from the current template host list #
                template.hosts.remove(template.hosts[count])
                continue

            # Iterate through list of regex host discovery matches #
            for match in discovery_match:
                # Attempt to parse out IP address from host discovery match #
                ip_addr = re.search(regex_obj.re_ip, match)
                # If an IP address was matched/parsed #
                if ip_addr:
                    # Append Ip address to current templates host list #
                    template.hosts.append(ip_addr.group(0))

            count += 1

    return template_list


def template_loader(conf_obj: object) -> list:
    """
    Iterates through the template files in the Active directory and loads their yaml data in to a
    scan object instance, which is then added to the template list.

    :param conf_obj:  The program configuration instance.
    :return:  The populated scan template list.
    """
    templates = []

    # Iterate through the scan templates in the Templates dir #
    for item in conf_obj.template_path.iterdir():
        # If the current item is a file and has YAML file extension #
        if item.is_file() and item.name.endswith('.yml'):
            # Format the current iteration file path #
            template_path = conf_obj.template_path / item.name
            # Load the yaml data from disk #
            template_data = file_handler(template_path, 'r', conf_obj.logger, yaml=True)
            # Initialize organizational template instance #
            scan_obj = ScanConfig()
            # Parse in organizational data from yaml with validation methods #
            scan_obj.organization = scan_obj.parse_client(template_data['scanner']['client'])
            scan_obj.hosts = scan_obj.parse_hosts(template_data['scanner']['hosts'])
            scan_obj.time = scan_obj.parse_time(template_data['scanner']['time'])
            # Append client template class to template list #
            templates.append(scan_obj)

    return templates


def main():
    """
    Loads the config file, depending on config file settings, either runs ping scan to identify
    hosts or already has target host in config file, and launches the scan process on target hosts
    based on the available number of cpu's.

    :return:  Nothing
    """
    # Get the current working directory #
    cwd = Path.cwd()

    # If potential yaml config file passed into to program #
    if len(sys.argv) > 1:
        # Format passed in argument as path #
        config_path = cwd / 'Configs' / sys.argv[1]

        # If the passed in configuration file does not exist or is not a yaml file #
        if not config_path.exists() or not str(config_path).endswith('yml'):
            # Prompt user for yaml config file #
            config_path = config_input(cwd)

    # If no args were passed in #
    else:
        # Prompt user for yaml config file #
        config_path = config_input(cwd)

    # Load the YAML configuration file #
    config_data = file_handler(config_path, 'r', yaml=True)
    # Parse program config data into class #
    config_obj = ConfigClass(cwd, config_data)

    # Compile program regex and return as instance #
    re_obj = RegexHandler()
    # Initialize scan service function class #
    service_obj = ServiceClass()

    # Call the scan template loader function #
    scan_templates = template_loader(config_obj)
    # Iterate through populated scan template list and perform host
    # discovery on network CIDRs to add new hosts to client template #
    scan_templates = asyncio.run(host_discovery(re_obj, scan_templates))
    # Sort the client templates based on scan time, otherwise first come first serve #
    sorted_templates = sort_templates(scan_templates)

    line = f'+{"=" * 98}+'

    print(line)
    print(r'''
                                                                               .:oxxxdc,            
                                                                           .;xXMMMMMMMMMWO,         
                                                                        'oKMMMMMMWOxxOXMMMMO        
                                                       .;::;'.      .:kNMMMMMMKo'      '0MMMK.      
                                                   'o0MMMMMMMMKo.'o0MMMMMMWkc.           kMMMN.     
                                               .:kNMMMMMMMWMMMMMMMMMMMMKd,                oMMMW,    
                             ...            'oKMMMMMMWOc.  .0MMMMMMWOc.                    cMMMW.   
                         ,dKWMMMWKx:    .:kWMMMMMMKd,     .XMMMMXd,'ck.                     dMMMx   
                     .:kWMMMMMMMMMMMWxoKMMMMMMWk:.        0MMMW:  :MMMW'                    dMMMx   
                  'o0MMMMMMXd;'';oNMMMMMMMW0l'            MMMMl    cMMMW'                  cMMMW.   
               ,xNWWWWWW0c.      lWWWWWXx; .              NWWWo     oWWWk               ;xNMMMN'    
             .. '.. '  ........ .......... '..   .'. ....  .... .   .....  .      . .  .   kKl      
        .   .c'.o.. c: ' .; :.. l.  '. l.. o.:    x ;.  .;:.  ',l  ;.   ;..c. ;l  c.;, '            
      lXK   .:  l   ' c; .; :     o '. l   o',    x ,'  .,;.  '.l  ;'   ;. :.'.', c. .:'            
    .NMMX.   .  ...    .    ... .''... ....,...   .   ..   .''..,''. .. ...'.'..,..                 
   .WMMMN:                       cMMMM:  .XMMMo         .l0MMMMNMMMMN0kOKMMMMMXx;                   
   lMMMM.                         ,WMMMo 'NMMd      .:xNMMMMWkc..l0WMMMMMMNkc.                      
   cMMMM                           .XMMMO..x,    ;dKMMMMMKo'        .',,..                          
    XMMMk                         .'.0MMMMOoccoOWMMMMWk:.                                           
    .XMMMO                     'oXMMc ;OMMMMMMMMMMKo,                                               
      0MMMK.                ;xNMMMMNk.   ,cdxxdl,.                                                  
       OMMMX.           .cOWMMMMXd,                                                                 
        xMMMN,       'oKMMMMM0l.                                                                    
         lWMMMXdlclkNMMMMWk:.                                                                       
          .oXMMMMMMMMMKo,                                                                           
             .;coooc,. 
    ''')
    print(line)

    # Launch asynchronous event processing function #
    asyncio.run(task_executor(sorted_templates, config_obj, re_obj, service_obj))

    # If markdown generate from output is set to True in config file #
    if config_obj.markdown:
        # Crawl through the Output director and copy text format to markdown #
        markdown_formatter(config_obj.out_dir, root_logger, re_obj)

    print(line)


class LocalQueueHandler(logging.handlers.QueueHandler):
    """
    Acts as the thread handler that processes logging records in queue.
    """
    def emit(self, record: logging.LogRecord):
        """
        Takes a record from the logging queue listener and enqueues the record to the local
        logging system

        :param record:  The logging record to be handled.
        :return:  Nothing
        """
        try:
            # Add log record to the logging queue #
            self.enqueue(record)

        # If async task was already cancelled #
        except asyncio.CancelledError:
            raise

        # If unknown exception occurred #
        except Exception:
            self.handleError(record)


def setup_logging():
    """
    Moves the log handlers to a separate thread, replacing handlers on the root logger with a
    LocalQueueHandler. After a queue listener is initialized with the original handlers.

    :return:  Nothing
    """
    handlers = []
    # Get the root logging handler #
    root = logging.getLogger()
    # Get the local queue handler #
    handler = LocalQueueHandler(queue)
    # Assign local queue handler to root handler #
    root.addHandler(handler)

    # Iterate through the root handlers #
    for current_handler in root.handlers[:]:
        # If the current iteration is not a handler #
        if current_handler is not handler:
            # Remove handler from the root handlers #
            root.removeHandler(current_handler)
            # Add handler to handlers list #
            handlers.append(current_handler)

    # Establish logging queue listener with extracted root handlers and start handler #
    listener = logging.handlers.QueueListener(queue, *handlers, respect_handler_level=True)
    listener.start()


if __name__ == '__main__':
    RET = 0
    # Record the start time #
    start_time = time.perf_counter()
    # Setup asyncio based logging system #
    setup_logging()
    # Establish logging formatter #
    formatter = logging.Formatter('%(asctime)s %(lineno)4d@%(filename)-24s[%(levelname)s]>>'
                                  '  %(message)s')
    # Get the root logger #
    root_logger = logging.getLogger()
    # Create a handler using the LocalQueueHandler #
    queue_handler = LocalQueueHandler(queue)

    try:
        main()

    # If unknown exception occurs #
    except Exception as ex:
        # Print error, log, and set error return code #
        print_err(f'Unknown exception occurred: {ex}')
        logging.exception('Unknown exception occurred: %s', ex)
        RET = 1

    # Record the finish time #
    exec_time = time.perf_counter() - start_time

    # Print and log total execution time #
    print(f'\n[!] Execution time: {exec_time}')
    logging.info('Execution time: %s', exec_time)
    # Sleep second to ensure logging thread logs info before exit #
    time.sleep(1)

    sys.exit(RET)
